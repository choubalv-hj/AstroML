{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa60e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from astropy.io import fits\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table,Column,MaskedColumn,QTable\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import scipy.constants as C\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import metrics\n",
    "import sklearn.model_selection\n",
    "import optuna\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "mpl.rcParams.update({'font.size': 20})\n",
    "mpl.rcParams['lines.linewidth'] = 1.5\n",
    "mpl.rcParams['axes.linewidth']=2\n",
    "font = {'family': 'sans-serif',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 12,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd88f7bd",
   "metadata": {},
   "source": [
    "# Version of Python Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3522fb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy 1.21.5\n",
      "Pandas 1.5.1\n",
      "XGBoost 1.7.1\n",
      "Optuna 3.0.3\n",
      "Scikit-learn 1.0.2\n"
     ]
    }
   ],
   "source": [
    "print('Numpy',np.__version__)\n",
    "print('Pandas',pd.__version__)\n",
    "print('XGBoost',xgb.__version__)\n",
    "print('Optuna',optuna.__version__)\n",
    "print('Scikit-learn',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7a497c",
   "metadata": {},
   "source": [
    "# Read the parent sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3fe0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=ascii.read('./all_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287eaf7",
   "metadata": {},
   "source": [
    "# Input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "390a6df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of training sources: 3710 \n",
      "N of training extragalactic objects: 3396 \n",
      "N of training stars: 314\n",
      "N of blind-test sources: 2051 \n",
      "N of blind-test extragalactic objects: 1896 \n",
      "N of blind-test stars: 155\n",
      "N of training sources: 3396 \n",
      "N of training quasars: 723 \n",
      "N of training galaxies: 2673\n",
      "N of blind-test sources: 1896 \n",
      "N of blind-test quasars: 393 \n",
      "N of blind-test galaxies: 1503\n"
     ]
    }
   ],
   "source": [
    "all_para=pd.DataFrame(\n",
    "    {\n",
    "        \"fuv_nuv\":pd.Series(data['fuv_nuv'],dtype='float'),\n",
    "        \"nuv_u\":pd.Series(data['nuv_u'],dtype='float'),\n",
    "        \"nuv_g\":pd.Series(data['nuv_g'],dtype='float'),\n",
    "        \"u_g\":pd.Series(data['u_g'],dtype='float'),\n",
    "        \"g_r\":pd.Series(data['g_r'],dtype='float'),\n",
    "        \"r_i\":pd.Series(data['r_i'],dtype='float'),\n",
    "        \"i_z\":pd.Series(data['i_z'],dtype='float'),\n",
    "        \"z_y\":pd.Series(data['z_y'],dtype='float'),\n",
    "        \"y_J\":pd.Series(data['y_J'],dtype='float'),\n",
    "        \"J_H\":pd.Series(data['J_H'],dtype='float'),\n",
    "        \"H_K\":pd.Series(data['H_K'],dtype='float'),\n",
    "        \"K_3p6\":pd.Series(data['K_3p6'],dtype='float'),\n",
    "        \"y_3p6\":pd.Series(data['y_3p6'],dtype='float'),\n",
    "        \"i_3p6\":pd.Series(data['i_3p6'],dtype='float'),\n",
    "        \"r_3p6\":pd.Series(data['r_3p6'],dtype='float'),\n",
    "        \"z_3p6\":pd.Series(data['z_3p6'],dtype='float'),\n",
    "        \"g_3p6\":pd.Series(data['g_3p6'],dtype='float'),\n",
    "        \"ir3p6_4p5\":pd.Series(data['ir3p6_4p5'],dtype='float'),\n",
    "        \"morpho_i\":pd.Series(data['morpho_i'],dtype='float'),\n",
    "        \"morpho_r\":pd.Series(data['morpho_r'],dtype='float'),\n",
    "        \"morpho_z\":pd.Series(data['morpho_z'],dtype='float'),\n",
    "        \"morpho_y\":pd.Series(data['morpho_y'],dtype='float'),\n",
    "        \"morpho_g\":pd.Series(data['morpho_g'],dtype='float'),\n",
    "    }\n",
    ")\n",
    "all_para=all_para.round(3)\n",
    "\n",
    "\n",
    "#classifier 1\n",
    "training_s1=np.where((data['train_test_flag']==1)&\\\n",
    "                    ((data['classlabel_s1']==0)|(data['classlabel_s1']==1)))\n",
    "training_s1_ext=np.where((data['train_test_flag']==1)&\\\n",
    "                    ((data['classlabel_s1']==1)))\n",
    "training_s1_star=np.where((data['train_test_flag']==1)&\\\n",
    "                    ((data['classlabel_s1']==0)))\n",
    "print('N of training sources:',np.size(training_s1),\\\n",
    "     '\\nN of training extragalactic objects:',np.size(training_s1_ext),\\\n",
    "     '\\nN of training stars:',np.size(training_s1_star))\n",
    "\n",
    "\n",
    "all_training_para_s1=pd.DataFrame(\n",
    "    {\n",
    "        \"fuv_nuv\":pd.Series(data['fuv_nuv'][training_s1],dtype='float'),\n",
    "        \"nuv_u\":pd.Series(data['nuv_u'][training_s1],dtype='float'),\n",
    "        \"nuv_g\":pd.Series(data['nuv_g'][training_s1],dtype='float'),\n",
    "        \"u_g\":pd.Series(data['u_g'][training_s1],dtype='float'),\n",
    "        \"g_r\":pd.Series(data['g_r'][training_s1],dtype='float'),\n",
    "        \"r_i\":pd.Series(data['r_i'][training_s1],dtype='float'),\n",
    "        \"i_z\":pd.Series(data['i_z'][training_s1],dtype='float'),\n",
    "        \"z_y\":pd.Series(data['z_y'][training_s1],dtype='float'),\n",
    "        \"y_J\":pd.Series(data['y_J'][training_s1],dtype='float'),\n",
    "        \"J_H\":pd.Series(data['J_H'][training_s1],dtype='float'),\n",
    "        \"H_K\":pd.Series(data['H_K'][training_s1],dtype='float'),\n",
    "        \"K_3p6\":pd.Series(data['K_3p6'][training_s1],dtype='float'),\n",
    "        \"y_3p6\":pd.Series(data['y_3p6'][training_s1],dtype='float'),\n",
    "        \"i_3p6\":pd.Series(data['i_3p6'][training_s1],dtype='float'),\n",
    "        \"r_3p6\":pd.Series(data['r_3p6'][training_s1],dtype='float'),\n",
    "        \"z_3p6\":pd.Series(data['z_3p6'][training_s1],dtype='float'),\n",
    "        \"g_3p6\":pd.Series(data['g_3p6'][training_s1],dtype='float'),\n",
    "        \"ir3p6_4p5\":pd.Series(data['ir3p6_4p5'][training_s1],dtype='float'),\n",
    "        \"morpho_i\":pd.Series(data['morpho_i'][training_s1],dtype='float'),\n",
    "        \"morpho_r\":pd.Series(data['morpho_r'][training_s1],dtype='float'),\n",
    "        \"morpho_z\":pd.Series(data['morpho_z'][training_s1],dtype='float'),\n",
    "        \"morpho_y\":pd.Series(data['morpho_y'][training_s1],dtype='float'),\n",
    "        \"morpho_g\":pd.Series(data['morpho_g'][training_s1],dtype='float'),\n",
    "    }\n",
    ")\n",
    "all_training_para_s1=all_training_para_s1.round(3)\n",
    "all_training_label_s1=data['classlabel_s1'][training_s1]\n",
    "\n",
    "\n",
    "\n",
    "test_s1=np.where((data['train_test_flag']==0)&\\\n",
    "                    ((data['classlabel_s1']==0)|(data['classlabel_s1']==1)))\n",
    "test_s1_ext=np.where((data['train_test_flag']==0)&\\\n",
    "                    ((data['classlabel_s1']==1)))\n",
    "test_s1_star=np.where((data['train_test_flag']==0)&\\\n",
    "                    ((data['classlabel_s1']==0)))\n",
    "print('N of blind-test sources:',np.size(test_s1),\\\n",
    "     '\\nN of blind-test extragalactic objects:',np.size(test_s1_ext),\\\n",
    "     '\\nN of blind-test stars:',np.size(test_s1_star))\n",
    "all_test_para_s1=pd.DataFrame(\n",
    "    {\n",
    "        \"fuv_nuv\":pd.Series(data['fuv_nuv'][test_s1],dtype='float'),\n",
    "        \"nuv_u\":pd.Series(data['nuv_u'][test_s1],dtype='float'),\n",
    "        \"nuv_g\":pd.Series(data['nuv_g'][test_s1],dtype='float'),\n",
    "        \"u_g\":pd.Series(data['u_g'][test_s1],dtype='float'),\n",
    "        \"g_r\":pd.Series(data['g_r'][test_s1],dtype='float'),\n",
    "        \"r_i\":pd.Series(data['r_i'][test_s1],dtype='float'),\n",
    "        \"i_z\":pd.Series(data['i_z'][test_s1],dtype='float'),\n",
    "        \"z_y\":pd.Series(data['z_y'][test_s1],dtype='float'),\n",
    "        \"y_J\":pd.Series(data['y_J'][test_s1],dtype='float'),\n",
    "        \"J_H\":pd.Series(data['J_H'][test_s1],dtype='float'),\n",
    "        \"H_K\":pd.Series(data['H_K'][test_s1],dtype='float'),\n",
    "        \"K_3p6\":pd.Series(data['K_3p6'][test_s1],dtype='float'),\n",
    "        \"y_3p6\":pd.Series(data['y_3p6'][test_s1],dtype='float'),\n",
    "        \"i_3p6\":pd.Series(data['i_3p6'][test_s1],dtype='float'),\n",
    "        \"r_3p6\":pd.Series(data['r_3p6'][test_s1],dtype='float'),\n",
    "        \"z_3p6\":pd.Series(data['z_3p6'][test_s1],dtype='float'),\n",
    "        \"g_3p6\":pd.Series(data['g_3p6'][test_s1],dtype='float'),\n",
    "        \"ir3p6_4p5\":pd.Series(data['ir3p6_4p5'][test_s1],dtype='float'),\n",
    "        \"morpho_i\":pd.Series(data['morpho_i'][test_s1],dtype='float'),\n",
    "        \"morpho_r\":pd.Series(data['morpho_r'][test_s1],dtype='float'),\n",
    "        \"morpho_z\":pd.Series(data['morpho_z'][test_s1],dtype='float'),\n",
    "        \"morpho_y\":pd.Series(data['morpho_y'][test_s1],dtype='float'),\n",
    "        \"morpho_g\":pd.Series(data['morpho_g'][test_s1],dtype='float'),\n",
    "    }\n",
    ")\n",
    "all_test_para_s1=all_test_para_s1.round(3)\n",
    "all_test_label_s1=data['classlabel_s1'][test_s1]\n",
    "\n",
    "\n",
    "#classifier 2\n",
    "training_s2=np.where((data['train_test_flag']==1)&\\\n",
    "                    ((data['classlabel_s2']==0)|(data['classlabel_s2']==1)))\n",
    "training_s2_qso=np.where((data['train_test_flag']==1)&\\\n",
    "                    ((data['classlabel_s2']==1)))\n",
    "training_s2_gal=np.where((data['train_test_flag']==1)&\\\n",
    "                    ((data['classlabel_s2']==0)))\n",
    "print('N of training sources:',np.size(training_s2),\\\n",
    "     '\\nN of training quasars:',np.size(training_s2_qso),\\\n",
    "     '\\nN of training galaxies:',np.size(training_s2_gal))\n",
    "\n",
    "all_training_para_s2=pd.DataFrame(\n",
    "    {\n",
    "        \"fuv_nuv\":pd.Series(data['fuv_nuv'][training_s2],dtype='float'),\n",
    "        \"nuv_u\":pd.Series(data['nuv_u'][training_s2],dtype='float'),\n",
    "        \"nuv_g\":pd.Series(data['nuv_g'][training_s2],dtype='float'),\n",
    "        \"u_g\":pd.Series(data['u_g'][training_s2],dtype='float'),\n",
    "        \"g_r\":pd.Series(data['g_r'][training_s2],dtype='float'),\n",
    "        \"r_i\":pd.Series(data['r_i'][training_s2],dtype='float'),\n",
    "        \"i_z\":pd.Series(data['i_z'][training_s2],dtype='float'),\n",
    "        \"z_y\":pd.Series(data['z_y'][training_s2],dtype='float'),\n",
    "        \"y_J\":pd.Series(data['y_J'][training_s2],dtype='float'),\n",
    "        \"J_H\":pd.Series(data['J_H'][training_s2],dtype='float'),\n",
    "        \"H_K\":pd.Series(data['H_K'][training_s2],dtype='float'),\n",
    "        \"K_3p6\":pd.Series(data['K_3p6'][training_s2],dtype='float'),\n",
    "        \"y_3p6\":pd.Series(data['y_3p6'][training_s2],dtype='float'),\n",
    "        \"i_3p6\":pd.Series(data['i_3p6'][training_s2],dtype='float'),\n",
    "        \"r_3p6\":pd.Series(data['r_3p6'][training_s2],dtype='float'),\n",
    "        \"z_3p6\":pd.Series(data['z_3p6'][training_s2],dtype='float'),\n",
    "        \"g_3p6\":pd.Series(data['g_3p6'][training_s2],dtype='float'),\n",
    "        \"ir3p6_4p5\":pd.Series(data['ir3p6_4p5'][training_s2],dtype='float'),\n",
    "        \"morpho_i\":pd.Series(data['morpho_i'][training_s2],dtype='float'),\n",
    "        \"morpho_r\":pd.Series(data['morpho_r'][training_s2],dtype='float'),\n",
    "        \"morpho_z\":pd.Series(data['morpho_z'][training_s2],dtype='float'),\n",
    "        \"morpho_y\":pd.Series(data['morpho_y'][training_s2],dtype='float'),\n",
    "        \"morpho_g\":pd.Series(data['morpho_g'][training_s2],dtype='float'),\n",
    "    }\n",
    ")\n",
    "all_training_para_s2=all_training_para_s2.round(3)\n",
    "all_training_label_s2=data['classlabel_s2'][training_s2]\n",
    "\n",
    "\n",
    "\n",
    "test_s2=np.where((data['train_test_flag']==0)&\\\n",
    "                    ((data['classlabel_s2']==0)|(data['classlabel_s2']==1)))\n",
    "test_s2_qso=np.where((data['train_test_flag']==0)&\\\n",
    "                    ((data['classlabel_s2']==1)))\n",
    "test_s2_gal=np.where((data['train_test_flag']==0)&\\\n",
    "                    ((data['classlabel_s2']==0)))\n",
    "print('N of blind-test sources:',np.size(test_s2),\\\n",
    "     '\\nN of blind-test quasars:',np.size(test_s2_qso),\\\n",
    "     '\\nN of blind-test galaxies:',np.size(test_s2_gal))\n",
    "\n",
    "all_test_para_s2=pd.DataFrame(\n",
    "    {\n",
    "        \"fuv_nuv\":pd.Series(data['fuv_nuv'][test_s2],dtype='float'),\n",
    "        \"nuv_u\":pd.Series(data['nuv_u'][test_s2],dtype='float'),\n",
    "        \"nuv_g\":pd.Series(data['nuv_g'][test_s2],dtype='float'),\n",
    "        \"u_g\":pd.Series(data['u_g'][test_s2],dtype='float'),\n",
    "        \"g_r\":pd.Series(data['g_r'][test_s2],dtype='float'),\n",
    "        \"r_i\":pd.Series(data['r_i'][test_s2],dtype='float'),\n",
    "        \"i_z\":pd.Series(data['i_z'][test_s2],dtype='float'),\n",
    "        \"z_y\":pd.Series(data['z_y'][test_s2],dtype='float'),\n",
    "        \"y_J\":pd.Series(data['y_J'][test_s2],dtype='float'),\n",
    "        \"J_H\":pd.Series(data['J_H'][test_s2],dtype='float'),\n",
    "        \"H_K\":pd.Series(data['H_K'][test_s2],dtype='float'),\n",
    "        \"K_3p6\":pd.Series(data['K_3p6'][test_s2],dtype='float'),\n",
    "        \"y_3p6\":pd.Series(data['y_3p6'][test_s2],dtype='float'),\n",
    "        \"i_3p6\":pd.Series(data['i_3p6'][test_s2],dtype='float'),\n",
    "        \"r_3p6\":pd.Series(data['r_3p6'][test_s2],dtype='float'),\n",
    "        \"z_3p6\":pd.Series(data['z_3p6'][test_s2],dtype='float'),\n",
    "        \"g_3p6\":pd.Series(data['g_3p6'][test_s2],dtype='float'),\n",
    "        \"ir3p6_4p5\":pd.Series(data['ir3p6_4p5'][test_s2],dtype='float'),\n",
    "        \"morpho_i\":pd.Series(data['morpho_i'][test_s2],dtype='float'),\n",
    "        \"morpho_r\":pd.Series(data['morpho_r'][test_s2],dtype='float'),\n",
    "        \"morpho_z\":pd.Series(data['morpho_z'][test_s2],dtype='float'),\n",
    "        \"morpho_y\":pd.Series(data['morpho_y'][test_s2],dtype='float'),\n",
    "        \"morpho_g\":pd.Series(data['morpho_g'][test_s2],dtype='float'),\n",
    "    }\n",
    ")\n",
    "all_test_para_s2=all_test_para_s2.round(3)\n",
    "all_test_label_s2=data['classlabel_s2'][test_s2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40897b",
   "metadata": {},
   "source": [
    "# Use Optuna to Find Optimal Hyperparameters for Classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51807653",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 100\n",
    "N_FOLDS = 5\n",
    "CV_RESULT_DIR = \"./xgboost_cv_results_clf1\"    \n",
    "dtrain_s1=xgb.DMatrix(all_training_para_s1,label=all_training_label_s1,missing=999.000)\n",
    "\n",
    "def objective(trial):\n",
    "    param={\n",
    "            \"objective\":\"binary:logistic\",\n",
    "            \"booster\":\"gbtree\",\n",
    "            \"tree_method\":\"hist\",\n",
    "            \"eval_metric\":\"logloss\",\n",
    "            \"reg_lambda\":trial.suggest_float(\"reg_lambda\",0.1,10,step=0.1),\n",
    "            \"reg_alpha\":trial.suggest_float(\"reg_alpha\",0,10,step=0.1),\n",
    "            \"max_depth\":trial.suggest_int(\"max_depth\",5,10),\n",
    "            \"eta\":trial.suggest_float(\"eta\",0.1,0.3,step=0.1),\n",
    "            \"gamma\":trial.suggest_float(\"gamma\",0.1,1,step=0.1),\n",
    "            \"grow_policy\":\"depthwise\",\n",
    "            \"min_child_weight\":trial.suggest_int(\"min_child_weight\",1,10,step=1),\n",
    "            \"colsample_bytree\":1,\n",
    "            \"subsample\":1,\n",
    "            \"max_delta_step\":trial.suggest_float(\"max_delta_step\",0,10,step=1),\n",
    "            }\n",
    "\n",
    "    xgb_cv_results = xgb.cv(\n",
    "        params=param,\n",
    "        dtrain=dtrain_s1,\n",
    "        num_boost_round=100,\n",
    "        nfold=N_FOLDS,\n",
    "        stratified=True,\n",
    "        seed=SEED,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "    # Save cross-validation results.\n",
    "    filepath = os.path.join(CV_RESULT_DIR, \"{}.csv\".format(trial.number))\n",
    "    xgb_cv_results.to_csv(filepath, index=False)\n",
    "    # Extract the best score.\n",
    "    logloss = xgb_cv_results[\"test-logloss-mean\"].values[-1]\n",
    "    return logloss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(CV_RESULT_DIR):\n",
    "        os.mkdir(CV_RESULT_DIR)\n",
    "    study_step1=optuna.create_study(direction=\"minimize\")\n",
    "    study_step1.optimize(objective,n_trials=5000)\n",
    "    print(\"Number of finished trials: \", len(study_step1.trials))\n",
    "    #write down the best hyperparameter set\n",
    "    f=open('step1_best_param.txt',\"a+\")\n",
    "    f.write(\"Best trial:\")\n",
    "    btrial=study_step1.best_trial\n",
    "    f.write(\"  Value: {}\".format(btrial.value)+\"\\n\")\n",
    "        \n",
    "    param_step1={\"objective\":\"binary:logistic\",\n",
    "                     \"booster\":\"gbtree\",\n",
    "                     \"tree_method\":\"hist\",\n",
    "                     \"missing\":999.000,\n",
    "                     \"eval_metric\":\"logloss\",\n",
    "                     \"n_estimators\":100,\n",
    "                     \"reg_lambda\":np.around(study_step1.best_trial.params['reg_lambda'],decimals=1),\n",
    "                     \"reg_alpha\":np.around(study_step1.best_trial.params['reg_alpha'],decimals=1),\n",
    "                     \"max_depth\":study_step1.best_trial.params['max_depth'],\n",
    "                     \"learning_rate\":np.around(study_step1.best_trial.params['eta'],decimals=1),\n",
    "                     \"gamma\":np.around(study_step1.best_trial.params['gamma'],decimals=1),\n",
    "                     \"grow_policy\":\"depthwise\",\n",
    "                     \"min_child_weight\":np.around(study_step1.best_trial.params['min_child_weight'],decimals=1),\n",
    "                     \"colsample_bytree\":1,\n",
    "                     \"subsample\":1,\n",
    "                     \"max_delta_step\":study_step1.best_trial.params['max_delta_step']\n",
    "                    }\n",
    "           \n",
    "    f.write(str(param_step1)+'\\n')\n",
    "    f.close()\n",
    "    shutil.rmtree(CV_RESULT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c2536",
   "metadata": {},
   "source": [
    "# First Classifier: Extragalactic Objects versus Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12d3a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean logloss value of five-fold cross-validation: 0.01041666195816765\n",
      "Optimal hyperparameters: {'objective': 'binary:logistic', 'booster': 'gbtree', 'tree_method': 'hist', 'missing': 999.0, 'eval_metric': 'logloss', 'n_estimators': 100, 'reg_lambda': 0.4, 'reg_alpha': 0.2, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.4, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'colsample_bytree': 1, 'subsample': 1, 'max_delta_step': 10.0}\n",
      "We use p_ext>0.98 as the threshold of classify extragalactic objects.\n",
      "Classes:   QSOs/Galaxies (+) Stars(-)  \n",
      "5-fold Training Precision+:  0.9991\n",
      "5-fold Training Recall+:  0.9971\n",
      "5-fold Training Precision-:  0.9688\n",
      "5-fold Training Recall-:  0.9904\n"
     ]
    }
   ],
   "source": [
    "#optimal hyperparameters for classifier 1\n",
    "param_step1={'objective': 'binary:logistic', 'booster': 'gbtree', 'tree_method': 'hist', 'eval_metric': 'logloss', 'reg_lambda': 0.4, 'reg_alpha': 0.2, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.4, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'colsample_bytree': 1, 'subsample': 1, 'max_delta_step': 10.0}\n",
    "\n",
    "#XGBoost 5-fold cross-validation\n",
    "SEED = 100\n",
    "N_FOLDS = 5\n",
    "dtrain_s1=xgb.DMatrix(all_training_para_s1,label=all_training_label_s1,missing=999.000)\n",
    "xgb_cv_results = xgb.cv(\n",
    "    params=param_step1,\n",
    "    dtrain=dtrain_s1,\n",
    "    num_boost_round=100,\n",
    "    nfold=N_FOLDS,\n",
    "    stratified=True,\n",
    "    seed=SEED,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "print('Mean logloss value of five-fold cross-validation:',\\\n",
    "      xgb_cv_results[\"test-logloss-mean\"].values[-1])\n",
    "\n",
    "\n",
    "#construct Classifier 1\n",
    "param_step1={'objective': 'binary:logistic', 'booster': 'gbtree', 'tree_method': 'hist', 'missing': 999.0, 'eval_metric': 'logloss', 'n_estimators': 100, 'reg_lambda': 0.4, 'reg_alpha': 0.2, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.4, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'colsample_bytree': 1, 'subsample': 1, 'max_delta_step': 10.0}\n",
    "print('Optimal hyperparameters:',param_step1)\n",
    "clf1=xgb.XGBClassifier(**param_step1)\n",
    "training_pred_prob=sklearn.model_selection.cross_val_predict(clf1,all_training_para_s1,all_training_label_s1,cv=5,method='predict_proba')\n",
    "training_pred_pvalue_star=training_pred_prob[:,0]\n",
    "training_pred_pvalue_ext=training_pred_prob[:,1]\n",
    "pred_label_prob_step1_cv=np.zeros(np.size(training_s1))\n",
    "\n",
    "print('We use p_ext>0.98 as the threshold of classify extragalactic objects.')\n",
    "pred_label_prob_step1_cv[np.where(training_pred_pvalue_ext>=0.98)]=1\n",
    "pre_results_step1_cv=metrics.precision_recall_fscore_support(all_training_label_s1,pred_label_prob_step1_cv)\n",
    "preci_nega=pre_results_step1_cv[0][0]\n",
    "recal_nega=pre_results_step1_cv[1][0]\n",
    "    \n",
    "preci_posi=pre_results_step1_cv[0][1]\n",
    "recal_posi=pre_results_step1_cv[1][1]\n",
    "\n",
    "print('Classes:   QSOs/Galaxies (+) Stars(-)  ')\n",
    "print('5-fold Training Precision+: ',np.around(preci_posi,decimals=4))\n",
    "print('5-fold Training Recall+: ',np.around(recal_posi,decimals=4))\n",
    "print('5-fold Training Precision-: ',np.around(preci_nega,decimals=4))\n",
    "print('5-fold Training Recall-: ',np.around(recal_nega,decimals=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e36ac37",
   "metadata": {},
   "source": [
    "# Use Optuna to Find Optimal Hyperparameters for Classifier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f3f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 100\n",
    "N_FOLDS = 5\n",
    "CV_RESULT_DIR = \"./xgboost_cv_results_clf2\"\n",
    "dtrain_s2=xgb.DMatrix(all_training_para_s2,label=all_training_label_s2,missing=999.000)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    param={\n",
    "            \"objective\":\"binary:logistic\",\n",
    "            \"booster\":\"gbtree\",\n",
    "            \"tree_method\":\"hist\",\n",
    "            \"eval_metric\":\"logloss\",\n",
    "            \"reg_lambda\":trial.suggest_float(\"reg_lambda\",0.1,10,step=0.1),\n",
    "            \"reg_alpha\":trial.suggest_float(\"reg_alpha\",0,10,step=0.1),\n",
    "            \"max_depth\":trial.suggest_int(\"max_depth\",5,10),\n",
    "            \"eta\":trial.suggest_float(\"eta\",0.1,0.3,step=0.1),\n",
    "            \"gamma\":trial.suggest_float(\"gamma\",0.1,10,step=0.1),\n",
    "            \"grow_policy\":\"depthwise\",\n",
    "            \"min_child_weight\":trial.suggest_int(\"min_child_weight\",1,10,step=1),\n",
    "            \"colsample_bytree\":1,\n",
    "            \"subsample\":1,\n",
    "            \"max_delta_step\":trial.suggest_float(\"max_delta_step\",0,10,step=1),\n",
    "            }\n",
    "    xgb_cv_results=xgb.cv(\n",
    "        params=param,\n",
    "        dtrain=dtrain_s2,\n",
    "        num_boost_round=100,\n",
    "        nfold=N_FOLDS,\n",
    "        stratified=True,\n",
    "        seed=SEED,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # Save cross-validation results.\n",
    "    filepath = os.path.join(CV_RESULT_DIR, \"{}.csv\".format(trial.number))\n",
    "    xgb_cv_results.to_csv(filepath, index=False)\n",
    "    # Extract the best score.\n",
    "    logloss = xgb_cv_results[\"test-logloss-mean\"].values[-1]\n",
    "    return logloss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(CV_RESULT_DIR):\n",
    "        os.mkdir(CV_RESULT_DIR)\n",
    "    study_step2=optuna.create_study(direction=\"minimize\")\n",
    "    study_step2.optimize(objective,n_trials=5000)\n",
    "    #write down the best hyperparameter set\n",
    "    f=open('step2_best_param.txt',\"a+\")\n",
    "    f.write(\"Best trial:\")\n",
    "    btrial=study_step2.best_trial\n",
    "    f.write(\"  Value: {}\".format(btrial.value)+\"\\n\")\n",
    "        \n",
    "    param_step2={\"objective\":\"binary:logistic\",\n",
    "                 \"booster\":\"gbtree\",\n",
    "                 \"tree_method\":\"hist\",\n",
    "                 \"missing\":999.000,\n",
    "                 \"eval_metric\":\"logloss\",\n",
    "                 \"n_estimators\":100,\n",
    "                 \"reg_lambda\":np.around(study_step2.best_trial.params['reg_lambda'],decimals=1),\n",
    "                 \"reg_alpha\":np.around(study_step2.best_trial.params['reg_alpha'],decimals=1),\n",
    "                 \"max_depth\":study_step2.best_trial.params['max_depth'],\n",
    "                 \"learning_rate\":np.around(study_step2.best_trial.params['eta'],decimals=1),\n",
    "                 \"gamma\":np.around(study_step2.best_trial.params['gamma'],decimals=1),\n",
    "                 \"grow_policy\":\"depthwise\",\n",
    "                 \"min_child_weight\":np.around(study_step2.best_trial.params['min_child_weight'],decimals=1),\n",
    "                 \"colsample_bytree\":1,\n",
    "                 \"subsample\":1,\n",
    "                 \"max_delta_step\":study_step2.best_trial.params['max_delta_step']\n",
    "                    }\n",
    "           \n",
    "    f.write(str(param_step2)+'\\n')\n",
    "    f.close()\n",
    "    shutil.rmtree(CV_RESULT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d0187d",
   "metadata": {},
   "source": [
    "# Second Classifier: Quasars versus Galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a2c6965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean logloss value of five-fold cross-validation: 0.0534823920031788\n",
      "{'objective': 'binary:logistic', 'booster': 'gbtree', 'tree_method': 'hist', 'missing': 999.0, 'eval_metric': 'logloss', 'n_estimators': 100, 'reg_lambda': 7.0, 'reg_alpha': 0.5, 'max_depth': 10, 'learning_rate': 0.3, 'gamma': 0.1, 'grow_policy': 'depthwise', 'min_child_weight': 3, 'colsample_bytree': 1, 'subsample': 1, 'max_delta_step': 7.0}\n",
      "We use p_ext>0.95 as the threshold of classify quasars.\n",
      "Classes:  QSOs (+) Galaxies(-)\n",
      "5-fold Training Precision+:  0.9888\n",
      "5-fold Training Recall+:  0.8534\n",
      "5-fold Training Precision-:  0.9618\n",
      "5-fold Training Recall-:  0.9974\n"
     ]
    }
   ],
   "source": [
    "#optimal hyperparameters for classifier 2\n",
    "param_step2={'objective': 'binary:logistic', 'booster': 'gbtree', 'tree_method': 'hist', 'eval_metric': 'logloss', 'reg_lambda': 7.0, 'reg_alpha': 0.5, 'max_depth': 10, 'learning_rate': 0.3, 'gamma': 0.1, 'grow_policy': 'depthwise', 'min_child_weight': 3, 'colsample_bytree': 1, 'subsample': 1, 'max_delta_step': 7.0}\n",
    "\n",
    "#XGBoost 5-fold cross-validation\n",
    "SEED = 100\n",
    "N_FOLDS = 5\n",
    "dtrain_s2=xgb.DMatrix(all_training_para_s2,label=all_training_label_s2,missing=999.000)\n",
    "xgb_cv_results = xgb.cv(\n",
    "    params=param_step2,\n",
    "    dtrain=dtrain_s2,\n",
    "    num_boost_round=100,\n",
    "    nfold=N_FOLDS,\n",
    "    stratified=True,\n",
    "    seed=SEED,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "print('Mean logloss value of five-fold cross-validation:',\\\n",
    "      xgb_cv_results[\"test-logloss-mean\"].values[-1])\n",
    "param_step2={'objective': 'binary:logistic', 'booster': 'gbtree', 'tree_method': 'hist', 'missing': 999.0, 'eval_metric': 'logloss', 'n_estimators': 100, 'reg_lambda': 7.0, 'reg_alpha': 0.5, 'max_depth': 10, 'learning_rate': 0.3, 'gamma': 0.1, 'grow_policy': 'depthwise', 'min_child_weight': 3, 'colsample_bytree': 1, 'subsample': 1, 'max_delta_step': 7.0}\n",
    "print(param_step2)\n",
    "clf2=xgb.XGBClassifier(**param_step2)\n",
    "\n",
    "training_pred_prob=sklearn.model_selection.cross_val_predict(clf2,all_training_para_s2,all_training_label_s2,cv=5,method='predict_proba')\n",
    "training_pred_pvalue_gal=training_pred_prob[:,0]\n",
    "training_pred_pvalue_qso=training_pred_prob[:,1]\n",
    "pred_label_prob_step2_cv=np.zeros(np.size(training_s2))\n",
    "\n",
    "print('We use p_ext>0.95 as the threshold of classify quasars.')\n",
    "pred_label_prob_step2_cv[np.where(training_pred_pvalue_qso>=0.95)]=1\n",
    "pre_results_step2_cv=metrics.precision_recall_fscore_support(all_training_label_s2,pred_label_prob_step2_cv)\n",
    "preci_nega=pre_results_step2_cv[0][0]\n",
    "recal_nega=pre_results_step2_cv[1][0]\n",
    "    \n",
    "preci_posi=pre_results_step2_cv[0][1]\n",
    "recal_posi=pre_results_step2_cv[1][1]\n",
    "\n",
    "print('Classes:  QSOs (+) Galaxies(-)')\n",
    "print('5-fold Training Precision+: ',np.around(preci_posi,decimals=4))\n",
    "print('5-fold Training Recall+: ',np.around(recal_posi,decimals=4))\n",
    "print('5-fold Training Precision-: ',np.around(preci_nega,decimals=4))\n",
    "print('5-fold Training Recall-: ',np.around(recal_nega,decimals=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5e0718",
   "metadata": {},
   "source": [
    "# Apply Classifier 1 & 2 to Parent Sample and Evaluating Performance from the Results of Blind-test Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ef27a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of training sample quasars as ext: 723\n",
      "N of training sample quasars as qso: 651\n",
      "N of predicted quasars in parent sample: 2784\n",
      "N of predicted stars, galaxies, and quasars in the XMM-LSS region: 18546 74996 1591 \n",
      "Better X-ray and multi-wavelength coverage in the XMM-LSS region\n",
      "N of SDSS quasars, stars, and galaxies in the blind-test region: 393 155 1503\n",
      "N of predicted true SDSS quasars, stars, and galaxies in the blind-test sample: 344 147 1495\n",
      "N of predicted blind-test sample SDSS quasars, stars, and galaxies: 345 158 1548\n",
      "Reliability Completeness (blind-test sample)\n",
      "Quasar: 0.9971 0.8753\n",
      "Galaxy: 0.9658 0.9947\n",
      "Star: 0.9304 0.9484\n"
     ]
    }
   ],
   "source": [
    "# calculate the probability of each source in parent sample\n",
    "param_step1={'objective': 'binary:logistic', 'booster': 'gbtree', 'tree_method': 'hist', 'missing': 999.0, 'eval_metric': 'logloss', 'n_estimators': 100, 'reg_lambda': 0.4, 'reg_alpha': 0.2, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.4, 'grow_policy': 'depthwise', 'min_child_weight': 1, 'colsample_bytree': 1, 'subsample': 1, 'max_delta_step': 10.0}\n",
    "clf1=xgb.XGBClassifier(**param_step1)\n",
    "clf1.fit(all_training_para_s1,all_training_label_s1)\n",
    "\n",
    "pred_step1_pvalue=clf1.predict_proba(all_para)\n",
    "pred_pvalue_sta=pred_step1_pvalue[:,0]\n",
    "pred_pvalue_ext=pred_step1_pvalue[:,1]\n",
    "\n",
    "param_step2={'objective': 'binary:logistic', 'booster': 'gbtree', 'tree_method': 'hist', 'missing': 999.0, 'eval_metric': 'logloss', 'n_estimators': 100, 'reg_lambda': 7.0, 'reg_alpha': 0.5, 'max_depth': 10, 'learning_rate': 0.3, 'gamma': 0.1, 'grow_policy': 'depthwise', 'min_child_weight': 3, 'colsample_bytree': 1, 'subsample': 1, 'max_delta_step': 7.0}\n",
    "clf2=xgb.XGBClassifier(**param_step2)\n",
    "clf2.fit(all_training_para_s2,all_training_label_s2)\n",
    "\n",
    "pred_step2_pvalue=clf2.predict_proba(all_para)\n",
    "pred_pvalue_gal=pred_step2_pvalue[:,0]\n",
    "pred_pvalue_qso=pred_step2_pvalue[:,1]\n",
    "\n",
    "thre_ext=0.98\n",
    "thre_qso=0.95\n",
    "\n",
    "\n",
    "print('N of training sample quasars as ext:',\\\n",
    "      np.size(np.where((data['train_test_flag']==1)&\\\n",
    "                       (pred_pvalue_ext>thre_ext)&(data['classlabel_s2']==1))))\n",
    "print('N of training sample quasars as qso:',\\\n",
    "      np.size(np.where((data['train_test_flag']==1)&\\\n",
    "                       (pred_pvalue_ext>thre_ext)&(pred_pvalue_qso>thre_qso)&(data['classlabel_s2']==1))))\n",
    "\n",
    "\n",
    "print('N of predicted quasars in parent sample:',\\\n",
    "     np.size(pred_qso_all))\n",
    "\n",
    "#generatet the pvalue file of all predicted quasars\n",
    "data_output=QTable([data['ra_parent'][pred_qso_all],\\\n",
    "             data['dec_parent'][pred_qso_all],\\\n",
    "             pred_pvalue_sta[pred_qso_all],\\\n",
    "             pred_pvalue_ext[pred_qso_all],\\\n",
    "             pred_pvalue_gal[pred_qso_all],\\\n",
    "             pred_pvalue_qso[pred_qso_all]],\\\n",
    "            names=['ra_parent',\\\n",
    "                   'dec_parent',\\\n",
    "                   'pred_star_prob',\\\n",
    "                   'pred_ext_prob',\\\n",
    "                   'pred_gal_prob',\\\n",
    "                   'pred_qso_prob'])\n",
    "ascii.write(data_output,'./predqso_all_pvalues.csv',format='csv',overwrite=True)\n",
    "\n",
    "\n",
    "pred_sta_xmm=np.where((data['train_test_flag']==1)&(pred_pvalue_ext<=thre_ext))\n",
    "pred_gal_xmm=np.where((data['train_test_flag']==1)&(pred_pvalue_ext>thre_ext)&\\\n",
    "                       (pred_pvalue_qso<thre_qso))\n",
    "pred_qso_xmm=np.where((data['train_test_flag']==1)&(pred_pvalue_ext>thre_ext)&\\\n",
    "                       (pred_pvalue_qso>thre_qso))\n",
    "pred_qso_all=np.where((pred_pvalue_ext>thre_ext)&\\\n",
    "                       (pred_pvalue_qso>thre_qso))\n",
    "\n",
    "print('N of predicted stars, galaxies, and quasars in the XMM-LSS region:',\\\n",
    "      np.size(pred_sta_xmm),\\\n",
    "      np.size(pred_gal_xmm),\\\n",
    "      np.size(pred_qso_xmm),\\\n",
    "     '\\nBetter X-ray and multi-wavelength coverage in the XMM-LSS region')\n",
    "\n",
    "\n",
    "test_qso=np.where((data['train_test_flag']==0)&\\\n",
    "                  (data['classlabel_s2']==1))\n",
    "test_star=np.where((data['train_test_flag']==0)&\\\n",
    "                  (data['classlabel_s1']==0))\n",
    "test_gal=np.where((data['train_test_flag']==0)&\\\n",
    "                  (data['classlabel_s2']==0))\n",
    "print('N of SDSS quasars, stars, and galaxies in the blind-test region:',\\\n",
    "     np.size(test_qso),\\\n",
    "     np.size(test_star),\\\n",
    "     np.size(test_gal))\n",
    "\n",
    "\n",
    "pred_star_test_true=np.where((data['train_test_flag']==0)&(pred_pvalue_ext<=thre_ext)&\\\n",
    "                           (data['classlabel_s1']==0))\n",
    "pred_gal_test_true=np.where((data['train_test_flag']==0)&(pred_pvalue_ext>thre_ext)&\\\n",
    "                       (pred_pvalue_qso<=thre_qso)&\\\n",
    "                           (data['classlabel_s2']==0))\n",
    "pred_qso_test_true=np.where((data['train_test_flag']==0)&(pred_pvalue_ext>thre_ext)&\\\n",
    "                       (pred_pvalue_qso>thre_qso)&\\\n",
    "                           (data['classlabel_s2']==1))\n",
    "\n",
    "print('N of predicted true SDSS quasars, stars, and galaxies in the blind-test sample:',\\\n",
    "     np.size(pred_qso_test_true),\\\n",
    "     np.size(pred_star_test_true),\\\n",
    "     np.size(pred_gal_test_true))\n",
    "\n",
    "pred_star_blindtest=np.where((data['train_test_flag']==0)&\\\n",
    "                           (pred_pvalue_ext<=thre_ext)&\\\n",
    "                           ((data['classlabel_s1']==0)|(data['classlabel_s1']==1)))\n",
    "pred_gal_blindtest=np.where((data['train_test_flag']==0)&\\\n",
    "                           (pred_pvalue_ext>thre_ext)&\\\n",
    "                           (pred_pvalue_qso<=thre_qso)&\\\n",
    "                           ((data['classlabel_s2']==0)|(data['classlabel_s2']==1)|(data['classlabel_s1']==0)))\n",
    "pred_quasar_blindtest=np.where((data['train_test_flag']==0)&\\\n",
    "                            (pred_pvalue_ext>thre_ext)&\\\n",
    "                            (pred_pvalue_qso>thre_qso)&\\\n",
    "                           ((data['classlabel_s2']==0)|(data['classlabel_s2']==1)))\n",
    "print('N of predicted blind-test sample SDSS quasars, stars, and galaxies:',\\\n",
    "     np.size(pred_quasar_blindtest),\\\n",
    "     np.size(pred_star_blindtest),\\\n",
    "     np.size(pred_gal_blindtest))\n",
    "\n",
    "relia_qso=np.around(np.size(pred_qso_test_true)/np.size(pred_quasar_blindtest),decimals=4)\n",
    "relia_star=np.around(np.size(pred_star_test_true)/np.size(pred_star_blindtest),decimals=4)\n",
    "relia_gal=np.around(np.size(pred_gal_test_true)/np.size(pred_gal_blindtest),decimals=4)\n",
    "comple_qso=np.around(np.size(pred_qso_test_true)/np.size(test_qso),decimals=4)\n",
    "comple_star=np.around(np.size(pred_star_test_true)/np.size(test_star),decimals=4)\n",
    "cpmple_gal=np.around(np.size(pred_gal_test_true)/np.size(test_gal),decimals=4)\n",
    "print('Reliability Completeness (blind-test sample)')\n",
    "print('Quasar:',relia_qso,comple_qso)\n",
    "print('Galaxy:',relia_gal,cpmple_gal)\n",
    "print('Star:',relia_star,comple_star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd62f7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
